{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN M1 D009.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bVZtxMi64mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2C5obAZ7c7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96a84bd3-dfbc-457c-b929-c4c338ecbb02"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf5r2uQpBX_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e37f4248-b707-489e-8b1c-ae11e8dd14f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cel-fruIBqU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "outputId": "3765eb15-d9c2-45eb-90b1-dfdb79dc5af6"
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Part 2 - Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Training',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Testing',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = 592,\n",
        "                         epochs = 25,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 198)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 592 images belonging to 2 classes.\n",
            "Found 196 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "592/592 [==============================] - 128s 216ms/step - loss: 0.4534 - acc: 0.7665 - val_loss: 0.8498 - val_acc: 0.6936\n",
            "Epoch 2/25\n",
            "592/592 [==============================] - 126s 213ms/step - loss: 0.1136 - acc: 0.9584 - val_loss: 1.3810 - val_acc: 0.6785\n",
            "Epoch 3/25\n",
            "592/592 [==============================] - 126s 213ms/step - loss: 0.0325 - acc: 0.9900 - val_loss: 1.5901 - val_acc: 0.6780\n",
            "Epoch 4/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 0.0155 - acc: 0.9958 - val_loss: 1.7486 - val_acc: 0.6841\n",
            "Epoch 5/25\n",
            "592/592 [==============================] - 126s 213ms/step - loss: 0.0200 - acc: 0.9937 - val_loss: 1.9143 - val_acc: 0.6529\n",
            "Epoch 6/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 1.6861 - val_acc: 0.6720\n",
            "Epoch 7/25\n",
            "592/592 [==============================] - 127s 215ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 2.3468 - val_acc: 0.6588\n",
            "Epoch 8/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 0.0181 - acc: 0.9945 - val_loss: 1.5686 - val_acc: 0.6981\n",
            "Epoch 9/25\n",
            "592/592 [==============================] - 125s 211ms/step - loss: 0.0060 - acc: 0.9978 - val_loss: 2.1771 - val_acc: 0.6689\n",
            "Epoch 10/25\n",
            "592/592 [==============================] - 125s 211ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 2.0238 - val_acc: 0.6742\n",
            "Epoch 11/25\n",
            "592/592 [==============================] - 125s 211ms/step - loss: 0.0045 - acc: 0.9983 - val_loss: 2.1586 - val_acc: 0.6731\n",
            "Epoch 12/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 0.0113 - acc: 0.9954 - val_loss: 2.3058 - val_acc: 0.6745\n",
            "Epoch 13/25\n",
            "592/592 [==============================] - 127s 214ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 2.4558 - val_acc: 0.6628\n",
            "Epoch 14/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 0.0092 - acc: 0.9971 - val_loss: 2.3642 - val_acc: 0.6481\n",
            "Epoch 15/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 2.2144 - val_acc: 0.6632\n",
            "Epoch 16/25\n",
            "592/592 [==============================] - 125s 211ms/step - loss: 2.1400e-04 - acc: 1.0000 - val_loss: 2.3083 - val_acc: 0.6888\n",
            "Epoch 17/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 1.2588e-04 - acc: 1.0000 - val_loss: 2.5427 - val_acc: 0.6736\n",
            "Epoch 18/25\n",
            "592/592 [==============================] - 125s 211ms/step - loss: 0.0173 - acc: 0.9946 - val_loss: 2.6029 - val_acc: 0.6731\n",
            "Epoch 19/25\n",
            "592/592 [==============================] - 126s 212ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 2.4423 - val_acc: 0.6531\n",
            "Epoch 20/25\n",
            "592/592 [==============================] - 125s 212ms/step - loss: 2.7208e-04 - acc: 0.9999 - val_loss: 2.5670 - val_acc: 0.6790\n",
            "Epoch 21/25\n",
            "592/592 [==============================] - 125s 211ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 2.2738 - val_acc: 0.6437\n",
            "Epoch 22/25\n",
            "592/592 [==============================] - 125s 212ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 2.2754 - val_acc: 0.6675\n",
            "Epoch 23/25\n",
            "592/592 [==============================] - 124s 210ms/step - loss: 3.3506e-04 - acc: 0.9999 - val_loss: 2.3714 - val_acc: 0.6589\n",
            "Epoch 24/25\n",
            "592/592 [==============================] - 125s 212ms/step - loss: 1.9259e-04 - acc: 0.9999 - val_loss: 2.4903 - val_acc: 0.6479\n",
            "Epoch 25/25\n",
            "592/592 [==============================] - 126s 213ms/step - loss: 6.1083e-05 - acc: 1.0000 - val_loss: 2.5199 - val_acc: 0.6419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88827b3f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9W84XeZGpr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Comments :\n",
        "\n",
        "#The output of the basic model implemented above shows overfitting.\n",
        "\n",
        "#Tried running the model with dropout still the model overfits\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Dropout(p=0.5))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "#We can try implementing the following to improve the accuracy\n",
        "#implement Early stopping\n",
        "#add L1,L2 regularization and dropout\n",
        "#reduce the model complexity\n",
        "#try different model architecture with transfer learning"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}